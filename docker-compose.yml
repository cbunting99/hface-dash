version: '2.4'

services:
  vllm-dashboard:
    build: .
    ports:
      - "8000:8000"
    volumes:
      - ./models:/app/models
      - ./data:/app/data
    environment:
      - CUDA_VISIBLE_DEVICES=0
    runtime: nvidia
    restart: unless-stopped